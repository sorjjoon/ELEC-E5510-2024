@article{PrabhavalkarEnd-to-End2024,
  author   = {Prabhavalkar, Rohit and Hori, Takaaki and Sainath, Tara N. and Schlüter, Ralf and Watanabe, Shinji},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {End-to-End Speech Recognition: A Survey},
  year     = {2024},
  volume   = {32},
  number   = {},
  pages    = {325-351},
  keywords = {Hidden Markov models;Training;Data models;Acoustics;Task analysis;Deep learning;Decoding;End-to-end;automatic speech recognition},
  doi      = {10.1109/TASLP.2023.3328283}
}
@article{sym11081018,
  author         = {Wang, Dong and Wang, Xiaodong and Lv, Shaohe},
  title          = {An Overview of End-to-End Automatic Speech Recognition},
  journal        = {Symmetry},
  volume         = {11},
  year           = {2019},
  number         = {8},
  article-number = {1018},
  url            = {https://www.mdpi.com/2073-8994/11/8/1018},
  issn           = {2073-8994},
  abstract       = {Automatic speech recognition, especially large vocabulary continuous speech recognition, is an important issue in the field of machine learning. For a long time, the hidden Markov model (HMM)-Gaussian mixed model (GMM) has been the mainstream speech recognition framework. But recently, HMM-deep neural network (DNN) model and the end-to-end model using deep learning has achieved performance beyond HMM-GMM. Both using deep learning techniques, these two models have comparable performances. However, the HMM-DNN model itself is limited by various unfavorable factors such as data forced segmentation alignment, independent hypothesis, and multi-module individual training inherited from HMM, while the end-to-end model has a simplified model, joint training, direct output, no need to force data alignment and other advantages. Therefore, the end-to-end model is an important research direction of speech recognition. In this paper we review the development of end-to-end model. This paper first introduces the basic ideas, advantages and disadvantages of HMM-based model and end-to-end models, and points out that end-to-end model is the development direction of speech recognition. Then the article focuses on the principles, progress and research hotspots of three different end-to-end models, which are connectionist temporal classification (CTC)-based, recurrent neural network (RNN)-transducer and attention-based, and makes theoretically and experimentally detailed comparisons. Their respective advantages and disadvantages and the possible future development of the end-to-end model are finally pointed out. Automatic speech recognition is a pattern recognition task in the field of computer science, which is a subject area of Symmetry.},
  doi            = {10.3390/sym11081018}
}

@inproceedings{GravesCTC2006,
  author  = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
  year    = {2006},
  month   = {01},
  pages   = {369-376},
  title   = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
  volume  = {2006},
  journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
  doi     = {10.1145/1143844.1143891}
}
@misc{graves2012sequencetransductionrecurrentneural,
  title         = {Sequence Transduction with Recurrent Neural Networks},
  author        = {Alex Graves},
  year          = {2012},
  eprint        = {1211.3711},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE},
  url           = {https://arxiv.org/abs/1211.3711}
}
@inproceedings{graves2013deeprecurrentneuralnetworks,
  author    = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title     = {Speech recognition with deep recurrent neural networks},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {6645-6649},
  keywords  = {Speech recognition;Recurrent neural networks;Training;Vectors;Acoustics;Noise;recurrent neural networks;deep neural networks;speech recognition},
  doi       = {10.1109/ICASSP.2013.6638947}
}
@inproceedings{sak17_interspeech,
  title     = {Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping},
  author    = {Haşim Sak and Matt Shannon and Kanishka Rao and Françoise Beaufays},
  year      = {2017},
  booktitle = {Interspeech 2017},
  pages     = {1298--1302},
  doi       = {10.21437/Interspeech.2017-1705},
  issn      = {2958-1796}
}
@inproceedings{NIPS2015_1068c6e4,
  author    = {Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Attention-Based Models for Speech Recognition},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2015/file/1068c6e4c8051cfd4e9ea8072e3189e2-Paper.pdf},
  volume    = {28},
  year      = {2015}
}
